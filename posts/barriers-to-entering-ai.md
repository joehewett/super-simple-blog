---
title: 'Barriers to entry in AI'
date: '2022-06-03T13:00:00.000Z'
description: 'Why does the average person not engage deeply with Artificial Intelligence?'
thumbnail: '/img/blog/thumbnail5.png'
---

# Barriers to entry in AI

I have been thinking about why the average person doesn't engage deeply with Artificial Intelligence, depite it being clearly the most important field of not just our time, but of our species. 

### Depth
It doesn’t help that only one of the words in “Artificial Intelligence” even has a definition that people agree on, and even then only just. A clear and concrete definition of “Intelligence” has, as of yet, evaded us. 

The most infamous example of this lack of clarity regarding our concept of intelligence came  with the conquest of Chess in 1997, with the fall of Gary Kasparov to DeepBlue. Until that point, it was a widely* held belief that Chess was one of the purest demonstrations of intellect - after all, how do you handle a board game that has 69 trillion possibilities within the first 5 moves, with anything other than raw, unadulterated intelligence? 

DeepBlue dispelled that myth rather quickly, and chess awkwardly changed teams in the intellectual venn diagram from “Intelligence Necessary” to “Just Another Solved Computing Problem”. This characteristic human trait of moving the goal posts of intelligence whenever we find out that seemingly intractable problems of intelligence can be solved with a trivial algorithm is called the “AI Effect”, and points towards instability in the foundations of our understanding of what “intelligence” really is. 

More evidence of the absurd depths that the problems in Artificial Intelligence dive to comes in the form of problems like Alignment. Those engaged in AI Alignment concern themselves with trying to figure out how they can outsmart systems more intelligent than themselves**, such that the values of more intelligent agents that we create have a precise replica of our own human values.  

If that wasn’t enough, consider the fact that at least since the time of Plato we’ve been actively trying to decipher our value systems, and after 2,500 years, what our values and morals are is still a subject of intense debate. Evidence suggests, however, that if we want to continue as the dominant species on Planet Earth we may need to not only agree on what our morals are, but also figure out a way of converting those values into binary such that the machine can understand them too.  Not only that, but there’s a good chance we only get one shot at getting this value specification right the first time. Oh and we’ve got about 50(?) years. Great. 


### Breadth 
Another reinforcement to the barrier of entry to AI is the breadth of knowledge that the field covers. 

Other subjects are hard. Computer Science is hard. Probability Theory is hard. Neuroscience is hard. Economics, Statistics, Game Theory, Decision Theory, Ethics, Philosophy, Language and Statistics are all complex topics with frontiers of knowledge well beyond where many are capable of venturing. But the pursuit of Artificial Intelligence has to draw from the frontier of all of these fields and more. The further we strive forwards towards the recreation of intelligence in silicon, the further we dig downwards into the depths of what it is that our intelligence has created. Perhaps that’s something to do with the fact that within the body of the fruits of intelligence lie the secrets to their creator itself. Regardless, solving intelligence requires that we use that tools that intelligence itself created.

This is not to say that Artificial Intelligence is the “most complex” thing of all - if you indulge yourself in any topic at a deep enough level you’ll most likely reach the saturation point of your brain long before the frontier of knowledge - it’s just that the level of context switching that is required when trying to think about AI holistically is somewhat intense. 

Just uttering the words “Rational agent” lands you 4 Wikipedia links past Von Neumann-Morgenstern 1944 trying to figure out which Economics modules you need to take to decipher expected utility theory. Take the “Attention is all you need” paper too seriously and you’ll be studying Cognitive Psychology before you get past the first word in the title. 


-* Widely, although groundbreaking research had existed for at least 48 years prior https://www.pi.infn.it/~carosi/chess/shannon.txt
-** This is a vast and perhaps tongue in cheek oversimplification of a very tricky topic. You can get a good overview of the body of work done by AI alignment researchers at https://www.alignmentforum.org/

