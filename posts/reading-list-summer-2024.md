---
title: "Reading List Summer 2024"
date: "2024-08-07T10:12:44.675Z"
description: "A list of posts and papers for the summer."
thumbnail: "/img/blog/thumbnail6.png"
---

## Must reads

[https://www.jasonwei.net/blog/evals](https://www.jasonwei.net/blog/evals)

[GAIA: A Benchmark for General AI Assistants](https://arxiv.org/pdf/2311.12983.pdf)

[MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation](https://arxiv.org/pdf/2310.03302)

[SWE-bench: Can Language Models Resolve Real-World GitHub Issues?](https://arxiv.org/abs/2310.06770)

[More tasks, human baselines, and preliminary results for GPT-4 and Claude - METR Blog](https://metr.org/blog/2024-08-06-update-on-evaluations/)

[Evaluating Frontier Models for Dangerous Capabilities](https://arxiv.org/pdf/2403.13793.pdf) (see the stuff on checkpoints here)

## Contamination

[A Careful Examination of Large Language Model Performance on Grade School Arithmetic](https://arxiv.org/abs/2405.00332)

[Rethinking Benchmark and Contamination for Language Models with Rephrased Samples](https://arxiv.org/pdf/2311.04850)

## pass@n just works

[Large Language Monkeys: Scaling Inference Compute with Repeated Sampling](https://arxiv.org/abs/2407.21787)

[The Larger the Better? Improved LLM Code-Generation via Budget Reallocation](https://arxiv.org/abs/2404.00725)

## Smarter methods for test time compute

[Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314)

[STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning](https://proceedings.neurips.cc/paper_files/paper/2022/file/639a9a172c044fbb64175b5fad42e9a5-Paper-Conference.pdf)

[https://epochai.org/blog/trading-off-compute-in-training-and-inference#combining-techniques](https://epochai.org/blog/trading-off-compute-in-training-and-inference#combining-techniques)

## This is why people have faith in test time compute (see side experiment IV part C)

[Scaling Scaling Laws with Board Games](https://arxiv.org/abs/2104.03113)

## Is performance on evals correlated?

[Observational Scaling Laws and the Predictability of Language Model Performance](https://arxiv.org/abs/2405.10938)

[Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?](https://arxiv.org/abs/2407.21792)

## How to build evals using AI

[Discovering Language Model Behaviors with Model-Written Evaluations](https://arxiv.org/abs/2212.09251)

## LM Reasoning

[Language Models (Mostly) Know What They Know](https://arxiv.org/pdf/2207.05221.pdf)

[Large Language Models Cannot Correct Their Reasoning Yet](https://arxiv.org/pdf/2310.01798.pdf)

[LLMs cannot find reasoning errors, but can correct them!](https://arxiv.org/pdf/2311.08516.pdf)
